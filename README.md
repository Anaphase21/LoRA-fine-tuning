# Fine-tuning with LoRA
This is one of many projects I completed as part of my NLP course in my master's studies. The files 'LoRA_fine_tuning.ipynb' and 'LoRA_fine_tuning_report.pdf' are the jupyter notebook, and report for the project respectively. In this project, I fine tuned the BLOOM 3B large language model on the Zulu language from the aya dataset from Huggingface using Low Rank Adaptation and Prefix tuning. The models were evaluated on an evaluation dataset, giving chrF++ and Bert scores of 28.83 and 0.86 respectively for LoRA. 
