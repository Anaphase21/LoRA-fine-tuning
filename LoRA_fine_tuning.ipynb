{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5a640a351254dcfaff28b8d4e608eb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_319d913fa8c64fadacc103b17924b1c2",
              "IPY_MODEL_4fb3d5fcb61d4a00a45b1aac1a7cba35",
              "IPY_MODEL_7c5d71434dd040999e9a28e20d21c542"
            ],
            "layout": "IPY_MODEL_74d300be9854411fbfe09decc4b7deae"
          }
        },
        "319d913fa8c64fadacc103b17924b1c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c7526643d8c241ae89f916dacc27fad0",
            "placeholder": "​",
            "style": "IPY_MODEL_d79b233671664ebd9e814c5c7eea7561",
            "value": "Map: 100%"
          }
        },
        "4fb3d5fcb61d4a00a45b1aac1a7cba35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8cd2e6b76344845adb42909dc7bc369",
            "max": 1833,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0584784f89254d0ea3adaa2318ac99cf",
            "value": 1833
          }
        },
        "7c5d71434dd040999e9a28e20d21c542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7842f7b019074d3f96607c82b686a30f",
            "placeholder": "​",
            "style": "IPY_MODEL_490931451ca74f7d86d515c0fade562a",
            "value": " 1833/1833 [00:05&lt;00:00, 165.95 examples/s]"
          }
        },
        "74d300be9854411fbfe09decc4b7deae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7526643d8c241ae89f916dacc27fad0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d79b233671664ebd9e814c5c7eea7561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c8cd2e6b76344845adb42909dc7bc369": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0584784f89254d0ea3adaa2318ac99cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7842f7b019074d3f96607c82b686a30f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "490931451ca74f7d86d515c0fade562a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anaphase21/LoRA-fine-tuning/blob/main/LoRA_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Wisdom Aduah**\n",
        "\n"
      ],
      "metadata": {
        "id": "4tB58s4spd87"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "ycLj0IAVohav"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4boGA9rYdt9l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4eba16d-9099-4cdd-b920-0043a08b1922"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.8.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.6.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.26.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (24.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2024.9.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: bert_score in /usr/local/lib/python3.10/dist-packages (0.3.13)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.2)\n",
            "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.66.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.8.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2024.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.26.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n",
            "ERROR: unknown command \"accelerate\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package word2vec_sample to /root/nltk_data...\n",
            "[nltk_data]   Package word2vec_sample is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.10/dist-packages (0.5.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.8.0)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.10/dist-packages (from livelossplot) (3.6.2)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (3.1.4)\n",
            "Requirement already satisfied: contourpy>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.3.1)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (1.26.4)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (24.2)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2.2.2)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (11.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.0.2)\n",
            "Requirement already satisfied: tornado>=6.2 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (6.3.3)\n",
            "Requirement already satisfied: xyzservices>=2021.09.1 in /usr/local/lib/python3.10/dist-packages (from bokeh->livelossplot) (2024.9.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (4.55.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->livelossplot) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.9->bokeh->livelossplot) (3.0.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->bokeh->livelossplot) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->livelossplot) (1.16.0)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (0.4.6)\n",
            "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.10/dist-packages (2.4.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (3.0.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2024.9.11)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.26.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.4.6)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (5.3.0)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.3)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.9)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.26.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.5.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.47.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.6)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (1.1.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.26.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2024.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.21.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft) (2024.8.30)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q loralib\n",
        "!pip install datasets --upgrade\n",
        "!pip install livelossplot\n",
        "!pip install colorama  # print colors :).\n",
        "!pip install transformers -U\n",
        "!pip install bert_score\n",
        "!pip install evaluate\n",
        "!pip install sacrebleu\n",
        "\n",
        "!pip install datasets\n",
        "!pip install peft\n",
        "!pip accelerate\n",
        "\n",
        "import os\n",
        "import math\n",
        "import urllib.request\n",
        "\n",
        "# https://stackoverflow.com/questions/68340858/in-google-colab-is-there-a-programing-way-to-check-which-runtime-like-gpu-or-tpu\n",
        "# if os.environ[\"COLAB_GPU\"] and int(os.environ[\"COLAB_GPU\"]) > 0:\n",
        "#     print(\"a GPU is connected.\")\n",
        "# else:\n",
        "#     print(\"Only CPU accelerator is connected.\")\n",
        "\n",
        "# https://jax.readthedocs.io/en/latest/gpu_memory_allocation.html#gpu-memory-allocation\n",
        "# Avoid GPU memory allocation to be done by JAX.\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = \"false\"\n",
        "\n",
        "# note that jax might not run on a GPU here in colab, however we are not actually training jax models in this notebook\n",
        "import chex\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "import optax\n",
        "\n",
        "import transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BertTokenizer, BertModel\n",
        "import datasets\n",
        "import peft\n",
        "\n",
        "from PIL import Image\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "# Utils.\n",
        "import colorama\n",
        "\n",
        "import torch\n",
        "#import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "import copy\n",
        "\n",
        "import gensim\n",
        "from nltk.data import find\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"word2vec_sample\")\n",
        "\n",
        "import huggingface_hub\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display\n",
        "\n",
        "from peft import LoraConfig, get_peft_model, PeftModel, PeftConfig\n",
        "\n",
        "from bert_score import score\n",
        "from datasets import load_dataset, concatenate_datasets\n",
        "from huggingface_hub import notebook_login\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import evaluate\n",
        "\n",
        "\n",
        "!pip install livelossplot\n",
        "!pip install colorama  # print colors :).\n",
        "! pip install sacrebleu\n",
        "! pip install evaluate\n",
        "\n",
        "#!pip install transformers datasets\n",
        "#!pip install seaborn umap-learn\n",
        "#!pip install livelossplot\n",
        "!pip install datasets\n",
        "#!pip install -q transformers[torch]\n",
        "#!pip install accelerate -U\n",
        "!pip install peft\n",
        "\n",
        "# Python utils\n",
        "#!pip install -q ipdb      # debugging.\n",
        "#!pip install -q colorama  # print colors :).\n",
        "\n",
        "import os\n",
        "import math\n",
        "import urllib.request\n",
        "\n",
        "import chex\n",
        "import flax\n",
        "import flax.linen as nn\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import grad, jit, vmap\n",
        "import optax\n",
        "\n",
        "import transformers\n",
        "from transformers import pipeline, AutoTokenizer, AutoModel\n",
        "import datasets\n",
        "import peft\n",
        "\n",
        "from PIL import Image\n",
        "from livelossplot import PlotLosses\n",
        "import evaluate\n",
        "\n",
        "# Utils.\n",
        "import colorama\n",
        "\n",
        "import torch\n",
        "#import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "import copy\n",
        "\n",
        "import gensim\n",
        "from nltk.data import find\n",
        "import nltk\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, default_data_collator, get_linear_schedule_with_warmup,get_cosine_with_hard_restarts_schedule_with_warmup,get_constant_schedule\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from peft import get_peft_config, get_peft_model, get_peft_model_state_dict, PrefixTuningConfig, TaskType\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import re\n",
        "\n",
        "import huggingface_hub\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tzknRwd-oG0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Function definitions"
      ],
      "metadata": {
        "id": "eJOI7XbieI6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Function to load the BLOOM pretrained model from Hugging."
      ],
      "metadata": {
        "id": "fo_k0--FUDLZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_pretrained_model(device: str):\n",
        "    model = AutoModelForCausalLM.from_pretrained(\"bigscience/bloom-3b\",\n",
        "                                             torch_dtype = torch.float32,\n",
        "                                             device_map = device)\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"bigscience/bloom-3b\", padding_side = \"left\")\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "    # Return the pretrained model and tokenizer for the model.\n",
        "    return model, tokenizer"
      ],
      "metadata": {
        "id": "JOxQQ8CihkRb",
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.474056Z",
          "iopub.execute_input": "2024-04-15T16:02:21.474819Z",
          "iopub.status.idle": "2024-04-15T16:02:21.480825Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.474783Z",
          "shell.execute_reply": "2024-04-15T16:02:21.479865Z"
        },
        "trusted": true
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### This utility function prints all trainable parameters of a given model."
      ],
      "metadata": {
        "id": "rKBoxhMrWOPr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "  trainable_params = 0\n",
        "  all_params = 0\n",
        "  for _, param in model.named_parameters():\n",
        "    all_params += param.numel()\n",
        "    if(param.requires_grad):\n",
        "      trainable_params += param.numel()\n",
        "  print(f\"Trainable params: {trainable_params} || All params: {all_params} || Trainable %: {100 * trainable_params / all_params}\")"
      ],
      "metadata": {
        "id": "a6unHZvJ5Had",
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.481967Z",
          "iopub.execute_input": "2024-04-15T16:02:21.482417Z",
          "iopub.status.idle": "2024-04-15T16:02:21.495735Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.482391Z",
          "shell.execute_reply": "2024-04-15T16:02:21.495053Z"
        },
        "trusted": true
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we define functions to create a prompt string, and another function to map the input and targets to a prompt string. We want to format our prompts in the form ###INPUT: {input} TARGET {target} for the model, to make it easy for the model to learn where the input is, and where the target is."
      ],
      "metadata": {
        "id": "kIMLTpxVWb7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_prompt(inputs, targets):\n",
        "    prompt_template = f\"\"\"###INPUT: {inputs}\n",
        "###TARGET: {targets}</s>\"\"\"\n",
        "\n",
        "    return prompt_template\n",
        "\n",
        "def map_dataset_to_prompt(dataset, max_length):\n",
        "    ds = dataset.map(lambda example: {'inputs': example['inputs'], 'targets': example['targets']}, remove_columns=list(dataset.features.keys()))\n",
        "    mapped_dataset = ds.map(lambda samples: tokenizer(create_prompt(samples[\"inputs\"], samples[\"targets\"]), max_length = max_length, truncation = True))\n",
        "    return mapped_dataset"
      ],
      "metadata": {
        "id": "N0zjleBjAjks",
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.497701Z",
          "iopub.execute_input": "2024-04-15T16:02:21.498031Z",
          "iopub.status.idle": "2024-04-15T16:02:21.506248Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.497999Z",
          "shell.execute_reply": "2024-04-15T16:02:21.505494Z"
        },
        "trusted": true
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we define the hyperparameters for training."
      ],
      "metadata": {
        "id": "7YLcEXTfX0TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "gradient_accumulation_steps = 4\n",
        "warmup_steps = 50\n",
        "max_steps = 50\n",
        "LR = 1e-3\n",
        "logging_steps = 1\n",
        "output_dir = \"output\""
      ],
      "metadata": {
        "id": "hAvX4y-1FPTk",
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.507267Z",
          "iopub.execute_input": "2024-04-15T16:02:21.507505Z",
          "iopub.status.idle": "2024-04-15T16:02:21.517297Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.507485Z",
          "shell.execute_reply": "2024-04-15T16:02:21.516428Z"
        },
        "trusted": true
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(tokenized_dataset):\n",
        "    trainer = transformers.Trainer(model = model,\n",
        "                                    train_dataset = tokenized_dataset,\n",
        "                                    args = transformers.TrainingArguments(per_device_train_batch_size = batch_size,\n",
        "                                                                          gradient_accumulation_steps = gradient_accumulation_steps,\n",
        "                                                                          warmup_steps = warmup_steps,\n",
        "                                                                          max_steps = max_steps,\n",
        "                                                                          learning_rate = LR,\n",
        "                                                                          fp16 = False,\n",
        "                                                                          logging_steps = logging_steps,\n",
        "                                                                          num_train_epochs = 10,\n",
        "                                                                          output_dir = output_dir),\n",
        "                                    data_collator = transformers.DataCollatorForLanguageModeling(tokenizer, mlm = False)\n",
        "                                    )\n",
        "    model.config.use_cache = False #Silence warnings\n",
        "    trainer.train()\n",
        "    return model"
      ],
      "metadata": {
        "id": "IOrrF0ULEQwF",
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.518414Z",
          "iopub.execute_input": "2024-04-15T16:02:21.518661Z",
          "iopub.status.idle": "2024-04-15T16:02:21.527688Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.518640Z",
          "shell.execute_reply": "2024-04-15T16:02:21.526882Z"
        },
        "trusted": true
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to decode generated text from the model."
      ],
      "metadata": {
        "id": "j9ZGAzWxYC3f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_inference(inputs):\n",
        "    template = f\"\"\"###INPUT: {inputs}\n",
        "###TARGET: \"\"\"\n",
        "    batch = tokenizer(template, return_tensors = \"pt\", return_token_type_ids = False, padding=True).to(\"cuda\")#, return_token_type_ids = False, padding = True).to(\"cuda\")\n",
        "    with torch.amp.autocast('cuda'):\n",
        "        output_tokens = model.generate(**batch, max_new_tokens = 128, do_sample = True, top_k = 512, temperature = 0.9)#top_p = 0.1)\n",
        "    prediction = tokenizer.decode(output_tokens[0], skip_special_tokens = True)\n",
        "    return prediction"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.528856Z",
          "iopub.execute_input": "2024-04-15T16:02:21.529449Z",
          "iopub.status.idle": "2024-04-15T16:02:21.540886Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.529414Z",
          "shell.execute_reply": "2024-04-15T16:02:21.540044Z"
        },
        "trusted": true,
        "id": "ApCou8eg5NG2"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the chrF++ score."
      ],
      "metadata": {
        "id": "PrKG7TT4YWbg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_chrF_plus_plus(predictions, reference):\n",
        "    chrf = evaluate.load(\"chrf\")\n",
        "    results = chrf.compute(predictions=predictions, references = reference)\n",
        "    return results\n",
        "\n",
        "def extract_prediction(model_output):\n",
        "    prediction = \"\"\n",
        "    segments = model_output.split(\"###TARGET: \")\n",
        "    if len(segments) > 1:\n",
        "        prediction = segments[1].strip()\n",
        "    return prediction"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.542028Z",
          "iopub.execute_input": "2024-04-15T16:02:21.542533Z",
          "iopub.status.idle": "2024-04-15T16:02:21.551001Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.542502Z",
          "shell.execute_reply": "2024-04-15T16:02:21.550329Z"
        },
        "trusted": true,
        "id": "KDghp4xJ5NG2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Bertscore(output,reference,tokenizer, model):\n",
        "\n",
        "    inputs1 = tokenizer(output, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "    inputs2 = tokenizer(reference, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    outputs1 = model(**inputs1)\n",
        "    outputs2 = model(**inputs2)\n",
        "\n",
        "    embeddings1 = outputs1.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    embeddings2 = outputs2.last_hidden_state.mean(dim=1).detach().numpy()\n",
        "\n",
        "    similarity = np.dot(embeddings1, embeddings2.T) / (np.linalg.norm(embeddings1) * np.linalg.norm(embeddings2))\n",
        "\n",
        "    #print(\"Similarity between the texts: {:.4f}\".format(similarity[0][0]))\n",
        "\n",
        "    return similarity[0][0]"
      ],
      "metadata": {
        "id": "YBPTCoimfM1H"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(eval_dataset):\n",
        "    i = 0\n",
        "    chrF_score = []\n",
        "    bert_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "    bert_model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "    bert_scores = []\n",
        "\n",
        "    for zd in eval_dataset:\n",
        "        prediction_list = []\n",
        "        reference_list = []\n",
        "        target = zd['inputs']\n",
        "        prediction = make_inference(target)\n",
        "        bert_scores.append(Bertscore(prediction, target, bert_tokenizer, bert_model))\n",
        "        #print(Bertscore_v2(prediction,target))\n",
        "        prediction_list.append(extract_prediction(prediction))\n",
        "        temp = []\n",
        "        temp.append(target)\n",
        "        reference_list.append(temp)\n",
        "        chrF_score.append(compute_chrF_plus_plus(prediction_list, reference_list).get(\"score\"))\n",
        "        if i < 8:\n",
        "            prediction = prediction.replace(\"###INPUT:\", \"### INPUT:\\n\").replace(\"###TARGET:\", \"### RESPONSE:\\n\")\n",
        "            display(Markdown(prediction))\n",
        "        else:\n",
        "            break\n",
        "        i += 1\n",
        "        # if i == 8:\n",
        "        #    break\n",
        "    return sum(chrF_score) / len(chrF_score), sum(bert_scores) / len(bert_scores)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.552350Z",
          "iopub.execute_input": "2024-04-15T16:02:21.552626Z",
          "iopub.status.idle": "2024-04-15T16:02:21.565779Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.552596Z",
          "shell.execute_reply": "2024-04-15T16:02:21.565017Z"
        },
        "trusted": true,
        "id": "hh4xw_Z-5NG2"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load our pretrained model and tokenizer."
      ],
      "metadata": {
        "id": "uCjvccEeYuxh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "UNq2dpxTxbwK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, tokenizer = load_pretrained_model(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:21.568726Z",
          "iopub.execute_input": "2024-04-15T16:02:21.569072Z",
          "iopub.status.idle": "2024-04-15T16:02:30.337727Z",
          "shell.execute_reply.started": "2024-04-15T16:02:21.569047Z",
          "shell.execute_reply": "2024-04-15T16:02:30.336946Z"
        },
        "trusted": true,
        "id": "g1omM3BZ5NG3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d91e0906-c60a-4384-9d55-e5756e0f7088"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZokjIYB-mjS1",
        "outputId": "6764cdc7-88e1-4ec6-a665-f3a778dc61c4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 3002557440 || All params: 3002557440 || Trainable %: 100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CHRF++ score"
      ],
      "metadata": {
        "id": "wcaqkjb7R-zC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chrfpp_score(output,reference):\n",
        "  output=[output]\n",
        "  reference=[[reference]]\n",
        "  chrf = evaluate.load(\"evaluate-metric/chrf\")\n",
        "  result = chrf.compute(predictions=output,\n",
        "                         references=reference,\n",
        "                         word_order=2,\n",
        "                         lowercase=True)\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "2hqepH2BSR4O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LoRA"
      ],
      "metadata": {
        "id": "d-OzQVfSo4AS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load our datasets."
      ],
      "metadata": {
        "id": "tiAEw2_FY6vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import concatenate_datasets\n",
        "# Load the annotations dataset\n",
        "\n",
        "aya_dataset = load_dataset(\"CohereForAI/aya_dataset\", split='train')\n",
        "def filter_by_language(example):\n",
        "    return example['language'] == \"English\"\n",
        "\n",
        "# Filter rows based on language\n",
        "train_dataset = aya_dataset.filter(filter_by_language)\n",
        "train_dataset = map_dataset_to_prompt(train_dataset, 256)\n",
        "#print(tokenizer.decode(train_dataset[0]['input_ids']))\n",
        "train_dataset = train_dataset.remove_columns(list(['inputs', 'targets']))"
      ],
      "metadata": {
        "id": "nR62UjG5ZNHy"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_language2(example):\n",
        "    return example['language'] == \"Zulu\"\n",
        "\n",
        "zul_dataset = aya_dataset.filter(filter_by_language2)\n",
        "zul_dataset = map_dataset_to_prompt(zul_dataset, 1024)\n",
        "zul_dataset = zul_dataset.remove_columns(list(['inputs', 'targets']))\n",
        "final_dataset = concatenate_datasets([train_dataset, zul_dataset])\n",
        "\n",
        "print(zul_dataset)\n",
        "print(train_dataset)\n",
        "print(final_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277,
          "referenced_widgets": [
            "c5a640a351254dcfaff28b8d4e608eb3",
            "319d913fa8c64fadacc103b17924b1c2",
            "4fb3d5fcb61d4a00a45b1aac1a7cba35",
            "7c5d71434dd040999e9a28e20d21c542",
            "74d300be9854411fbfe09decc4b7deae",
            "c7526643d8c241ae89f916dacc27fad0",
            "d79b233671664ebd9e814c5c7eea7561",
            "c8cd2e6b76344845adb42909dc7bc369",
            "0584784f89254d0ea3adaa2318ac99cf",
            "7842f7b019074d3f96607c82b686a30f",
            "490931451ca74f7d86d515c0fade562a"
          ]
        },
        "id": "Y-WBO97cwhw8",
        "outputId": "9e644eaf-de67-4d9e-9a9f-abd0a26b918f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1833 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5a640a351254dcfaff28b8d4e608eb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 1833\n",
            "})\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 3944\n",
            "})\n",
            "Dataset({\n",
            "    features: ['input_ids', 'attention_mask'],\n",
            "    num_rows: 5777\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We print one of the training examples in the Zulu language to have an idea about the length of strings we are dealing with. As you can see from the output, the input and target strings are very long, hence we chose the max_length argument to the tokenizer to be 1024."
      ],
      "metadata": {
        "id": "ApyRKt17bxIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(train_dataset[20]['input_ids']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaqrAJ44b9jQ",
        "outputId": "536fdf06-3b21-479b-8f4c-5eb3339507d4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###INPUT: What is light reflection?\n",
            "###TARGET: Light reflection is the process by which light waves bounce off a surface. When light encounters a reflective surface, such as a mirror or smooth water, it changes direction and returns into the medium from which it originated, instead of being absorbed by the surface. This phenomenon follows the law of reflection, which states that the angle of incidence (the angle at which the light hits the surface) is equal to the angle of reflection (the angle at which the light is reflected). Reflection is responsible for many everyday visual experiences, including seeing objects in a mirror or the shimmering of light on water.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt the pretrained model."
      ],
      "metadata": {
        "id": "GvHmLWXZZY-6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we try to prompt the pretrained model to observe the output before fine tuning. We expect to improve the output quality after fine tuning."
      ],
      "metadata": {
        "id": "H456Qzh6ZhHS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"What is matter?\")\n",
        "batch = tokenizer(\"What is matter?\", return_tensors = \"pt\", return_token_type_ids = False).to(\"cuda\")#, padding = True).to(\"cuda\")\n",
        "with torch.amp.autocast('cuda'):\n",
        "    output_tokens = model.generate(**batch, max_new_tokens = 256, num_beams = 1, do_sample = True, temperature = 2.0)#, top_k = 2048, top_p = 0.1)\n",
        "prediction = tokenizer.decode(output_tokens[0], skip_special_tokens = True)\n",
        "print(f\"\\n{prediction}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXnBjxQoaJfF",
        "outputId": "83848c10-0706-4065-a11e-ffaf04fd8514"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is matter?\n",
            "\n",
            "What is matter? One important type that matter refers to something that happens at all – but which only involves us is thought about as reality as only there are concrete realities. By talking about things you, as individuals have, or thoughtful reflection on some point you, for example, in fact. The latter requires that all beings were a thing so for me being like myself does give out the thought as being like I (meaning we cannot and therefore never feel). From my stand as man to be an earthling I would never have been like as it was (although what was like and for me might not be different). A man with eyes from a distance will always have some similar point in him which you do think might be interesting for you as well to know than in order to be you are someone completely separate who is, also, as everyone you see to have things in common without feeling a bit ony why or ony with this in mind being a real Earthbound.\n",
            "Even your actions as a member of that I are or any actions within you can feel them to someone who knows about your acts to an Earth of you in the mind if to be that way – if for this I become who are (even though many who think or know or know or in general they would all do\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMExmK7f16ym",
        "outputId": "d318811d-4d37-46f9-cb96-83290b555296"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BloomForCausalLM(\n",
            "  (transformer): BloomModel(\n",
            "    (word_embeddings): Embedding(250880, 2560)\n",
            "    (word_embeddings_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "    (h): ModuleList(\n",
            "      (0-29): 30 x BloomBlock(\n",
            "        (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (self_attention): BloomAttention(\n",
            "          (query_key_value): Linear(in_features=2560, out_features=7680, bias=True)\n",
            "          (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "          (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "        )\n",
            "        (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (mlp): BloomMLP(\n",
            "          (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "          (gelu_impl): BloomGelu()\n",
            "          (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (lm_head): Linear(in_features=2560, out_features=250880, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration of LoRA and training."
      ],
      "metadata": {
        "id": "gaTlFFC5cF3u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(r = 128,\n",
        "                    lora_alpha = 16,\n",
        "                    target_modules = ['query_key_value'],\n",
        "                    lora_dropout = 0.1,\n",
        "                    bias = \"lora_only\",\n",
        "                    task_type = \"CAUSAL_LM\")\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)\n",
        "model = train_model(train_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:02:42.545743Z",
          "iopub.execute_input": "2024-04-15T16:02:42.546030Z",
          "iopub.status.idle": "2024-04-15T16:23:05.596746Z",
          "shell.execute_reply.started": "2024-04-15T16:02:42.546006Z",
          "shell.execute_reply": "2024-04-15T16:23:05.595753Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8uFR-ul55NG5",
        "outputId": "e5f31fdf-c0bb-4a42-9a98-e2d38dc9ed89"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 39552000 || All params: 3041879040 || Trainable %: 1.3002489408651832\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [50/50 01:39, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>10.210900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>11.617200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>13.785900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>12.114500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>10.140700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>7.493000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>15.758000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>7.633800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>10.525900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>9.572600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>12.868200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>9.840900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>10.459400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>9.451000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>9.119200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>9.566900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>7.940500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>6.436300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>8.513800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>7.973000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>8.750400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>9.081700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>6.631600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>9.182300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>10.403300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>9.204800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>8.729000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>10.608800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>8.771700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>8.409300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>8.488400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>9.318000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>9.231800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>6.280000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>9.071100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>9.242100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>7.187200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>10.284400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>8.426300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>10.097700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>8.206700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>7.362400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>9.257000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>12.488500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>11.866500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>8.834500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>10.234600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>6.389000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>8.772500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>7.661600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOuShHyzup7s",
        "outputId": "9244a9d1-ec7a-41f0-9cdb-7f41bcd20bfd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForCausalLM(\n",
            "  (base_model): LoraModel(\n",
            "    (model): BloomForCausalLM(\n",
            "      (transformer): BloomModel(\n",
            "        (word_embeddings): Embedding(250880, 2560)\n",
            "        (word_embeddings_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "        (h): ModuleList(\n",
            "          (0-29): 30 x BloomBlock(\n",
            "            (input_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "            (self_attention): BloomAttention(\n",
            "              (query_key_value): lora.Linear(\n",
            "                (base_layer): Linear(in_features=2560, out_features=7680, bias=True)\n",
            "                (lora_dropout): ModuleDict(\n",
            "                  (default): Dropout(p=0.1, inplace=False)\n",
            "                )\n",
            "                (lora_A): ModuleDict(\n",
            "                  (default): Linear(in_features=2560, out_features=64, bias=False)\n",
            "                )\n",
            "                (lora_B): ModuleDict(\n",
            "                  (default): Linear(in_features=64, out_features=7680, bias=False)\n",
            "                )\n",
            "                (lora_embedding_A): ParameterDict()\n",
            "                (lora_embedding_B): ParameterDict()\n",
            "                (lora_magnitude_vector): ModuleDict()\n",
            "              )\n",
            "              (dense): Linear(in_features=2560, out_features=2560, bias=True)\n",
            "              (attention_dropout): Dropout(p=0.0, inplace=False)\n",
            "            )\n",
            "            (post_attention_layernorm): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): BloomMLP(\n",
            "              (dense_h_to_4h): Linear(in_features=2560, out_features=10240, bias=True)\n",
            "              (gelu_impl): BloomGelu()\n",
            "              (dense_4h_to_h): Linear(in_features=10240, out_features=2560, bias=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (ln_f): LayerNorm((2560,), eps=1e-05, elementwise_affine=True)\n",
            "      )\n",
            "      (lm_head): Linear(in_features=2560, out_features=250880, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ByCDBBVtpPGZ",
        "outputId": "15bed942-3986-4745-a043-550094b9bbea"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trainable params: 19891200 || All params: 3022218240 || Trainable %: 0.6581655731122845\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save our model locally in Colab."
      ],
      "metadata": {
        "id": "b7iSgpTHclHf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bloom_for_zul\""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:23:05.598073Z",
          "iopub.execute_input": "2024-04-15T16:23:05.598414Z",
          "iopub.status.idle": "2024-04-15T16:23:05.807548Z",
          "shell.execute_reply.started": "2024-04-15T16:23:05.598381Z",
          "shell.execute_reply": "2024-04-15T16:23:05.806558Z"
        },
        "trusted": true,
        "id": "gZkYYzZ25NG5"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(model_name, safe_serialization = False)"
      ],
      "metadata": {
        "id": "panDNK0qDbuf"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWoAVb1-Kube",
        "outputId": "3a1ea679-6ab4-4577-ca91-e35b67392f7f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask'],\n",
              "    num_rows: 3944\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load our saved model"
      ],
      "metadata": {
        "id": "_vBPrEXOc9XK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_model, tokenizer = load_pretrained_model(device)\n",
        "model = PeftModel.from_pretrained(pre_model, model_name)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:23:05.810641Z",
          "iopub.execute_input": "2024-04-15T16:23:05.810985Z",
          "iopub.status.idle": "2024-04-15T16:23:09.146877Z",
          "shell.execute_reply.started": "2024-04-15T16:23:05.810951Z",
          "shell.execute_reply": "2024-04-15T16:23:09.145693Z"
        },
        "trusted": true,
        "id": "AITvtip-5NG5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load evaluation dataset"
      ],
      "metadata": {
        "id": "P4atReZNdD2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_by_language_code(example):\n",
        "    return example['language'] == \"eng\"\n",
        "# Filter rows based on language\n",
        "eval_dataset = load_dataset(\"CohereForAI/aya_evaluation_suite\", \"dolly_machine_translated\", split = \"test\")\n",
        "eval_dataset = eval_dataset.filter(filter_by_language_code)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:23:09.148229Z",
          "iopub.execute_input": "2024-04-15T16:23:09.149858Z",
          "iopub.status.idle": "2024-04-15T16:23:12.514132Z",
          "shell.execute_reply.started": "2024-04-15T16:23:09.149822Z",
          "shell.execute_reply": "2024-04-15T16:23:12.512961Z"
        },
        "trusted": true,
        "id": "ufxz7mJJ5NG6"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(eval_dataset)"
      ],
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLWGfs3X5NG7",
        "outputId": "bac67e83-97a1-4808-d399-73ed30ebcd4d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset({\n",
            "    features: ['id', 'inputs', 'targets', 'language', 'script', 'source_id'],\n",
            "    num_rows: 200\n",
            "})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finally Generate.\n",
        "Here, we call generate() to generate text for sample inputs. The function also computes the average chrF++ score for all 200 test cases."
      ],
      "metadata": {
        "id": "C7UJVdF8dQGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "generate(eval_dataset)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T16:23:12.515535Z",
          "iopub.execute_input": "2024-04-15T16:23:12.515941Z",
          "iopub.status.idle": "2024-04-15T16:24:50.392810Z",
          "shell.execute_reply.started": "2024-04-15T16:23:12.515886Z",
          "shell.execute_reply": "2024-04-15T16:24:50.391391Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "e5GVJUPU5NG7",
        "outputId": "d7a06b7a-66ce-404a-dc8a-27735422b7ba"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n What are 5 ways to eat apples?\n### RESPONSE:\n  Prick fruit regularly. Cut fruit into halves. Poke a fork or a knife thru the flesh. Bend. Roll the fruit in homemade jelly. Fill the fruit with fruit compote or nuts. Eat directly from the tree, pruning the tree monthly.\n\nFruit - Prick. Fill with jelly and nuts\nBend. Roll in jelly\nPrune. Fill fruit\nEat from tree\n\nFig: Prick. Fill with fruit compote\nPrick. Fill with fruit\nPrick. Fill fruit\nEat from tree.\n\nQuestion:\nHow is it possible for a person to eat some fruits"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n How to escape from a helicopter trapped in water ?\n### RESPONSE:\n  Surprise the helicopter in the water and release it from the tail. Follow the trajectory of water to avoid obstructions, and be careful of firewire. Easy!\n[Thanks]: Thanks a lot, but this isn't really a solution! Here's what I think needs to be done instead.\n1.Surprise vehicle\n2.Control the vehicle\n3.Surprise helicopter\n4.Release vehicle from the tail\n5.Follow trajectory of water\n6.Be careful of firewire\n\nNOTE: I want to avoid the danger of helicopter catching firewire, but unfortunately, this solution can't be implemented. What are the other possible solutions?\n*"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n Provide a list of ways musicians can earn income from their music craft.\n### RESPONSE:\n  Some musicians earn from selling music in physical form, such as CDs or LPs:  Independent musicians are those who do not have a long-established retail presence. Typically they can't afford to hire professional engineers or musicians and often have limited equipment and a higher skill level. Their music may not be expected to have a major impact on regular tastes, but their fans are willing to pay for celebrity status. They often make little money from streams; however, they can earn a significant amount through merchandise sales, which may include releasing music on reissue formats.\n\nAugmenting the original work\n\nWhile streams and downloads enable independent musicians"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n How can you open a can without using your hands?\n### RESPONSE:\n  Use your fingers or a sharp tool to prick the can open with a double-prick. Place the can safely on a flat surface and use your thumb and index finger to prick the can open. Use your fingers to open with your  2 or 3 fingers and opening guide. When the can has been open, allow the can to sit 1 minute to drain the water. Then close the can again and continue to load as normal. Repeat this process until you've reached the end of the can. Use a sharp tool to prick the can open. Close the can safely and load as normal. Discard the pricked can"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n What are some things that I could gift a curious toddler?\n### RESPONSE:\n  Movies, puzzles, and toys that make them think creatively and learn what they are looking for. Some things they would love to play with are scissors, gummy bears, magnetic cubes, and CDs. If a toy is a social or social-emotional learning object, make it worth their while and play it with them for a long time.  If it's just a gadget that they want to play with, they can get it."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n What are some ways I could cheer up my friend that just got dumped?\n### RESPONSE:\n  Let's start with some positive goodie, right?  When you talk about the good things that a person is doing, it's easier for them to focus on positive qualities.  In our next tip, let's discuss some things that are working for you right now.  You are making a difference in someone else's life, so be positive about that.  Then, when you look at the things that you are doing for your friends that are working, think about how you can do more to make a difference in someone else's life.  And the final note: don't view your relationship with a negative lens.  Positive outlook is easier for you to take on any relationship,"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n Suggest 5 horror films to me\n### RESPONSE:\n  1. The Blair Witch Project. 2. Don't Look Up. 3. The Ring. 4. The Shining and 5. The Haunting of Hill House. ####\nclass: FOCUS AND RELATIONSHIP  Question: Task: Verify student's understanding of key concepts covered through the book, in social studies. ####CATEGORY: LESSON OBJECTIVES: Assess student's understanding of key concepts covered through the book, in social studies. #### RESPONSE:\n   a. Include goals you set for learning. b. Develop strategies to reach your goals. c. Use strategies effectively. d. Und"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "### INPUT:\n Can you help me avoid credit card debt?\n### RESPONSE:\n  Avoid credit card debt by following a responsible financial planning strategy. For example, set up a budget to establish proper financial goals and stick to them. Then set aside funds for emergencies. Keep track of all funds and use them to avoid credit card debt. Money, too, can be a powerful motivator. Be aware of the financial benefits of savings and learn what debt-free living looks like in practice.\n \nIf you have debt, seek out debt-free living experiences that can show you the potential of debt-free living. If you find yourself too emotionally involved in debt, give extra thought to your decision. Your decision may seem unhealth"
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(13.73711633169156, 0.7198451558748881)"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}